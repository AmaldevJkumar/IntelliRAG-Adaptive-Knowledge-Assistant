# Application Configuration
APP_NAME="RAG Knowledge Assistant"
APP_VERSION="1.0.0"
DEBUG=false
HOST=0.0.0.0
PORT=8000
API_PREFIX="/api/v1"

# Security
SECRET_KEY="your-secret-key-change-in-production"
ACCESS_TOKEN_EXPIRE_MINUTES=43200

# Database Configuration
DATABASE_URL="postgresql://rag_user:rag_password@localhost:5432/rag_db"
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=0

# Redis Cache Configuration
REDIS_URL="redis://localhost:6379/0"
REDIS_POOL_SIZE=10
CACHE_TTL=3600

# Vector Database Configuration
VECTOR_DB_TYPE="pinecone"  # pinecone, faiss, weaviate
PINECONE_API_KEY="your-pinecone-api-key"
PINECONE_ENVIRONMENT="us-west1-gcp-free"
PINECONE_INDEX_NAME="rag-knowledge-base"
PINECONE_DIMENSION=384
PINECONE_METRIC="cosine"

# FAISS Configuration (for local development)
FAISS_INDEX_PATH="./data/faiss_index"

# LLM Configuration
LLM_PROVIDER="openai"  # openai, anthropic, huggingface
OPENAI_API_KEY="your-openai-api-key"
OPENAI_MODEL="gpt-4"
OPENAI_TEMPERATURE=0.1
OPENAI_MAX_TOKENS=1000

# Anthropic Configuration
ANTHROPIC_API_KEY="your-anthropic-api-key"
ANTHROPIC_MODEL="claude-3-sonnet-20240229"

# Embedding Configuration
EMBEDDING_MODEL="sentence-transformers/all-MiniLM-L6-v2"
EMBEDDING_BATCH_SIZE=32
EMBEDDING_MAX_LENGTH=512

# Document Processing Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_FILE_SIZE=52428800  # 50MB
SUPPORTED_FILE_TYPES="pdf,docx,txt,md,html"

# Retrieval Configuration
RETRIEVAL_TOP_K=5
RETRIEVAL_SCORE_THRESHOLD=0.7
HYBRID_SEARCH_ALPHA=0.5
RERANK_TOP_K=20
RERANK_MODEL="ms-marco-MiniLM-L-6-v2"

# MLflow Configuration
MLFLOW_TRACKING_URI="http://localhost:5000"
MLFLOW_EXPERIMENT_NAME="rag-knowledge-assistant"
ENABLE_MLFLOW=true

# Monitoring Configuration
ENABLE_METRICS=true
ENABLE_FEEDBACK=true
LOG_LEVEL="INFO"
QUALITY_THRESHOLD=0.8
AUTO_RETRAIN_THRESHOLD=0.6
DRIFT_DETECTION_WINDOW=1000

# Performance Configuration
MAX_WORKERS=4
REQUEST_TIMEOUT=30
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=60

# Security Configuration
JWT_ALGORITHM="HS256"
CORS_ORIGINS="*"
ALLOWED_HOSTS="*"
