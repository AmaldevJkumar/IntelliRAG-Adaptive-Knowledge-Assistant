"""
Pytest configuration and fixtures for RAG Knowledge Assistant tests
"""

import pytest
import asyncio
import tempfile
import os
from unittest.mock import AsyncMock, MagicMock
from typing import Dict, Any

from fastapi.testclient import TestClient
from httpx import AsyncClient

# Import your app
from backend.app.main import app
from backend.app.config import get_settings, Settings


class TestSettings(Settings):
    """Test-specific settings"""
    DEBUG: bool = True
    TESTING: bool = True
    DATABASE_URL: str = "sqlite:///./test.db"
    REDIS_URL: str = "redis://localhost:6379/1"
    OPENAI_API_KEY: str = "test-key"
    VECTOR_DB_TYPE: str = "mock"
    ENABLE_METRICS: bool = False
    ENABLE_MLFLOW: bool = False
    LOG_LEVEL: str = "DEBUG"


@pytest.fixture(scope="session")
def event_loop():
    """Create an instance of the default event loop for the test session."""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()


@pytest.fixture
def test_settings():
    """Provide test-specific settings"""
    return TestSettings()


@pytest.fixture
def client():
    """Create a test client for the FastAPI app"""
    with TestClient(app) as test_client:
        yield test_client


@pytest.fixture
async def async_client():
    """Create an async test client"""
    async with AsyncClient(app=app, base_url="http://test") as ac:
        yield ac


@pytest.fixture
def mock_vector_store():
    """Mock vector store for testing"""
    mock_store = AsyncMock()
    
    # Mock similarity search
    mock_store.similarity_search_with_score.return_value = [
        ({
            "page_content": "Test document content",
            "metadata": {
                "document_id": "test_doc_1",
                "filename": "test.pdf",
                "source": "test_source"
            }
        }, 0.9),
        ({
            "page_content": "Another test document",
            "metadata": {
                "document_id": "test_doc_2", 
                "filename": "test2.pdf",
                "source": "test_source"
            }
        }, 0.8)
    ]
    
    # Mock add documents
    mock_store.add_documents.return_value = True
    
    # Mock delete document
    mock_store.delete_document.return_value = True
    
    # Mock stats
    mock_store.get_stats.return_value = {
        "total_vectors": 100,
        "dimension": 384
    }
    
    return mock_store


@pytest.fixture
def mock_llm():
    """Mock LLM for testing"""
    mock_llm = AsyncMock()
    
    # Mock generate
    mock_llm.generate.return_value = {
        "answer": "This is a test answer generated by the mock LLM.",
        "confidence_score": 0.85
    }
    
    # Mock streaming generate
    async def mock_stream():
        chunks = ["This ", "is ", "a ", "streaming ", "response."]
        for chunk in chunks:
            yield chunk
    
    mock_llm.generate_streaming.return_value = mock_stream()
    
    return mock_llm


@pytest.fixture
def mock_cache():
    """Mock cache for testing"""
    cache_storage = {}
    
    mock_cache = AsyncMock()
    
    async def mock_get(key, default=None):
        return cache_storage.get(key, default)
    
    async def mock_set(key, value, ttl=None):
        cache_storage[key] = value
        return True
    
    async def mock_delete(key):
        return cache_storage.pop(key, None) is not None
    
    mock_cache.get.side_effect = mock_get
    mock_cache.set.side_effect = mock_set
    mock_cache.delete.side_effect = mock_delete
    
    return mock_cache


@pytest.fixture
def sample_query_request():
    """Sample query request for testing"""
    return {
        "query": "What is machine learning?",
        "top_k": 5,
        "query_type": "hybrid",
        "include_sources": True,
        "confidence_threshold": 0.7
    }


@pytest.fixture
def sample_document():
    """Sample document for testing"""
    return {
        "content": "This is a sample document about machine learning and artificial intelligence.",
        "filename": "ml_guide.pdf",
        "source": "test_source",
        "metadata": {
            "author": "Test Author",
            "date": "2024-01-01",
            "category": "AI/ML"
        }
    }


@pytest.fixture
def temp_file():
    """Create a temporary file for testing"""
    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:
        f.write("This is test content for document processing.")
        temp_path = f.name
    
    yield temp_path
    
    # Cleanup
    if os.path.exists(temp_path):
        os.unlink(temp_path)


@pytest.fixture
def mock_embedding_model():
    """Mock embedding model for testing"""
    mock_model = MagicMock()
    
    # Mock encode method
    def mock_encode(texts, **kwargs):
        # Return mock embeddings (384-dimensional)
        import numpy as np
        if isinstance(texts, str):
            texts = [texts]
        return np.random.rand(len(texts), 384).astype(np.float32)
    
    mock_model.encode = mock_encode
    
    return mock_model


@pytest.fixture
def mock_pdf_content():
    """Mock PDF content for testing"""
    return """# Test Document

This is a test PDF document containing information about machine learning.

## Introduction

Machine learning is a subset of artificial intelligence that enables computers to learn and make decisions from data.

## Key Concepts

- Supervised Learning
- Unsupervised Learning  
- Reinforcement Learning

## Applications

Machine learning has applications in:
- Image recognition
- Natural language processing
- Recommendation systems
"""


@pytest.fixture
def auth_headers():
    """Authentication headers for testing"""
    # This would normally contain a valid JWT token
    return {"Authorization": "Bearer test-token"}


@pytest.fixture
def admin_headers():
    """Admin authentication headers for testing"""
    return {"Authorization": "Bearer admin-test-token"}


@pytest.fixture
async def setup_test_database():
    """Setup test database"""
    # In a real application, this would set up a test database
    # For now, we'll use in-memory storage
    test_data = {
        "documents": [],
        "queries": [],
        "users": []
    }
    
    yield test_data
    
    # Cleanup after test
    test_data.clear()


@pytest.fixture
def mock_openai_client():
    """Mock OpenAI client for testing"""
    mock_client = AsyncMock()
    
    # Mock chat completion
    mock_response = MagicMock()
    mock_response.choices = [
        MagicMock(message=MagicMock(content="This is a mock OpenAI response."))
    ]
    mock_response.usage = MagicMock(total_tokens=100)
    
    mock_client.chat.completions.create.return_value = mock_response
    
    return mock_client


@pytest.fixture
def mock_pinecone():
    """Mock Pinecone client for testing"""
    mock_pinecone = MagicMock()
    
    # Mock index
    mock_index = MagicMock()
    mock_index.query.return_value = MagicMock(
        matches=[
            MagicMock(
                id="test_1",
                score=0.9,
                metadata={"content": "Test content 1", "filename": "test1.pdf"}
            ),
            MagicMock(
                id="test_2", 
                score=0.8,
                metadata={"content": "Test content 2", "filename": "test2.pdf"}
            )
        ]
    )
    
    mock_index.upsert.return_value = True
    mock_index.delete.return_value = True
    
    mock_pinecone.Index.return_value = mock_index
    
    return mock_pinecone


# Pytest markers
def pytest_configure(config):
    """Configure pytest markers"""
    config.addinivalue_line("markers", "slow: marks tests as slow")
    config.addinivalue_line("markers", "integration: marks tests as integration tests")
    config.addinivalue_line("markers", "unit: marks tests as unit tests")
    config.addinivalue_line("markers", "api: marks tests as API tests")


# Pytest collection hooks
def pytest_collection_modifyitems(config, items):
    """Modify test collection"""
    for item in items:
        # Add markers based on test file location
        if "test_integration" in item.nodeid:
            item.add_marker(pytest.mark.integration)
        elif "test_unit" in item.nodeid:
            item.add_marker(pytest.mark.unit)
        elif "test_api" in item.nodeid:
            item.add_marker(pytest.mark.api)
        
        # Mark slow tests
        if "slow" in item.nodeid or "test_slow" in item.name:
            item.add_marker(pytest.mark.slow)


# Async test utilities
@pytest.fixture
def run_async():
    """Helper to run async functions in tests"""
    def _run(coro):
        loop = asyncio.get_event_loop()
        return loop.run_until_complete(coro)
    return _run
